{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('expand_frame_repr', True) \n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数: read_stk_data 运行了 0.0081秒\n",
      "函数: read_stk_data 运行了 1.7871秒\n",
      "函数: read_stk_data 运行了 0.0031秒\n",
      "函数: read_stk_data 运行了 1.456秒\n"
     ]
    }
   ],
   "source": [
    "from data_api import DataFeeder, DataAPI\n",
    "from factor_base import FactorBase\n",
    "\n",
    "# Instantiate the data interface\n",
    "d = DataFeeder() \n",
    "api = DataAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>return_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.039761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.059640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.028410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.031289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053977</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.023394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053978</th>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.069582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053979</th>\n",
       "      <td>2023-11-24</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.045808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053980</th>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.017599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053981</th>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.032242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10053982 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date stock_code  return_5\n",
       "0        2016-01-04  000001.SZ -0.039761\n",
       "1        2016-01-05  000001.SZ -0.059640\n",
       "2        2016-01-06  000001.SZ -0.028410\n",
       "3        2016-01-07  000001.SZ -0.043834\n",
       "4        2016-01-08  000001.SZ -0.031289\n",
       "...             ...        ...       ...\n",
       "10053977 2023-11-22  689009.SH -0.023394\n",
       "10053978 2023-11-23  689009.SH -0.069582\n",
       "10053979 2023-11-24  689009.SH -0.045808\n",
       "10053980 2023-11-27  689009.SH -0.017599\n",
       "10053981 2023-11-28  689009.SH -0.032242\n",
       "\n",
       "[10053982 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"/mnt/data/stocks/basic/processed_stock_trade_data.feather\")\n",
    "data = data[data.date >= \"2016-01-01\"][['date', 'stock_code', 'open', 'high', 'low', 'close', 'volume', 'total_turnover']]\n",
    "data['vwap'] = data.total_turnover / data.volume\n",
    "date_list = data.date.unique().tolist()\n",
    "def process_stock_group(group):\n",
    "    group = group[['date', 'vwap']].copy()\n",
    "    group.set_index('date', inplace=True)\n",
    "    group = group.reindex(date_list)\n",
    "    group[\"return_5\"] = (group.vwap.shift(-4) / group.vwap - 1).shift(-1)\n",
    "    return group.iloc[:-5,:]\n",
    "df_return = data.groupby('stock_code').apply(process_stock_group).reset_index()\n",
    "df_return.rename(columns={'level_1': 'date'}, inplace=True)\n",
    "df_return = df_return[['date', 'stock_code', 'return_5']]\n",
    "# df_return.to_feather(\"/mnt/research/data/temp/zhangsurui/E2E_NN/Round2/return_data.feather\")\n",
    "df_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:40<00:00, 20.31s/it]\n"
     ]
    }
   ],
   "source": [
    "def process_stock(stock_seq):\n",
    "    stock = stack_index[stock_seq]\n",
    "    if stock in df_rtn.index:\n",
    "        stock_rtn = df_rtn.loc[stock, \"return_5\"]\n",
    "        if ~np.isnan(stock_rtn):\n",
    "            y = stock_rtn\n",
    "            return y, stock_seq, stock\n",
    "    return None, None, None\n",
    "\n",
    "n_jobs = 200\n",
    "window_size = 5\n",
    "train_sample_list = []\n",
    "train_index_list = []\n",
    "test_sample_list = []\n",
    "test_index_list = []\n",
    "\n",
    "for date_seq in tqdm(range(window_size-1,window_size+1)):#len(date_list))):\n",
    "    \n",
    "    date_current = date_list[date_seq]\n",
    "    df_rtn = df_return.loc[df_return.date == date_current, [\"stock_code\", \"return_5\"]].set_index(\"stock_code\")\n",
    "    data_type = \"train\" if date_current.strftime(\"%Y-%m-%d\") < \"2022-01-01\" else \"test\"\n",
    "\n",
    "    date_window = date_list[date_seq-window_size+1:date_seq+1]\n",
    "    window_stack = []\n",
    "    for date in date_window:\n",
    "        data_mink = pd.read_feather(\"/mnt/data/stocks/mink/by_date/\"+date.strftime(\"%Y%m%d\")+\".feather\")\n",
    "        data_mink[\"stock_code\"] = data_mink.order_book_id.map(lambda x:api.code_transf(rqcode=x,verse=False))\n",
    "        data_mink[\"vwap\"] = data_mink.total_turnover / data_mink.volume\n",
    "        data_mink = data_mink[[\"stock_code\", \"datetime\", \"date\", \"time\", \"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]]\n",
    "        data_mink = data_mink[(data_mink.time != \"14:58:00\") & (data_mink.time != \"14:59:00\")]\n",
    "        data_mink.loc[data_mink.volume == 0, \"vwap\"] = data_mink.loc[data_mink.volume == 0, \"open\"]\n",
    "        window_stack.append(data_mink)\n",
    "    df_window = pd.concat(window_stack, axis=0)\n",
    "    if df_window.isna().any().any():\n",
    "        print(\"The window \" + date_current.strftime(\"%Y%m%d\") + \" contains unexpected NaN\")\n",
    "    stack_index = []\n",
    "    stack_numpy = []\n",
    "    for df in df_window.groupby(\"stock_code\"):\n",
    "        if len(df[1]) == 1190:\n",
    "            stack_index.append(df[0])\n",
    "            stack_numpy.append(df[1][[\"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]].to_numpy())\n",
    "    stack_numpy = np.array(stack_numpy)\n",
    "    # ts_pre_process\n",
    "    price_adj = np.tile(stack_numpy[:,0,0][:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "    for price in range(5):\n",
    "        stack_numpy[:,:,price] /= price_adj\n",
    "    volume_adj = stack_numpy[:,:,5].mean(axis=1)\n",
    "    volume_adj = np.tile(np.where(volume_adj < 1e-14, 1, volume_adj)[:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "    stack_numpy[:,:,5] /= volume_adj\n",
    "    # cs_pre_process\n",
    "    for feat in range(6):\n",
    "        cs_mean = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "        cs_std = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "        stack_numpy[:,:,feat] = np.where(cs_std < 1e-14, np.zeros_like(stack_numpy[:,:,feat]), (stack_numpy[:,:,feat] - cs_mean) / cs_std)\n",
    "\n",
    "    # # df_window = df_window.groupby(\"stock_code\").apply(ts_pre_process).reset_index(drop=True)\n",
    "    # # df_window = df_window.groupby(\"datetime\").apply(cs_pre_process).reset_index(drop=True)\n",
    "    # # df_window.to_feather(\"/mnt/research/data/temp/zhangsurui/E2E_NN/Round2/\"+data_type+\"/\"+date_current.strftime(\"%Y%m%d\")+\"_\"+data_type+\".feather\")\n",
    "\n",
    "    pool = Pool(n_jobs)\n",
    "    results = pool.map(process_stock, range(len(stack_index)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    batch_list = []\n",
    "    batch_y = []\n",
    "    batch_code = []\n",
    "    for result in results:\n",
    "        y, index, code = result\n",
    "        if y is not None:\n",
    "            batch_y.append(y)\n",
    "            batch_list.append(index)\n",
    "            batch_code.append(code)\n",
    "    batch_X = torch.Tensor(stack_numpy[batch_list])\n",
    "    batch_y = torch.Tensor(np.array(batch_y)[:,np.newaxis])\n",
    "\n",
    "    if data_type == \"train\":\n",
    "        train_sample_list.append((batch_X, batch_y))\n",
    "        train_index_list.append(batch_code)\n",
    "    else:\n",
    "        test_sample_list.append((batch_X, batch_y))\n",
    "        test_index_list.append(batch_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUNet(\n",
       "  (gru): GRU(6, 50, num_layers=2, batch_first=True, dropout=0.4)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GRUNet(\n",
       "  (gru): GRU(6, 50, num_layers=2, batch_first=True, dropout=0.4)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred_mean = torch.mean(y_pred)\n",
    "        y_true_mean = torch.mean(y_true)\n",
    "        y_pred_std = torch.std(y_pred)\n",
    "        y_true_std = torch.std(y_true)\n",
    "\n",
    "        cov = torch.mean((y_pred - y_pred_mean) * (y_true - y_true_mean))\n",
    "        IC = cov / (y_pred_std * y_true_std)\n",
    "\n",
    "        return -IC\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1, dropout_rate=0.4,random_seed=0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        # self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # out = self.batch_norm(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = GRUNet(input_size=6, hidden_size=50, num_layers=2, output_size=1, dropout_rate=0.4)\n",
    "criterion = PearsonCorrelationLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "total_train_loss = 0\n",
    "\n",
    "# for seq, labels in train_sample_list:\n",
    "#     seq, labels = seq.to(device), labels.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     y_pred = model(seq.float())\n",
    "#     single_loss = criterion(y_pred.squeeze(), labels.float().squeeze())\n",
    "#     single_loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     total_train_loss += single_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3885],\n",
       "        [0.3234],\n",
       "        [0.3767],\n",
       "        ...,\n",
       "        [0.2900],\n",
       "        [0.2241],\n",
       "        [0.3601]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, labels = train_sample_list[0][0].to(device), train_sample_list[0][1].to(device)\n",
    "optimizer.zero_grad()\n",
    "y_pred = model(seq.float())\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(y_pred.float(), labels.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0106, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.56 GiB is free. Process 137184 has 1.05 GiB memory in use. Including non-PyTorch memory, this process has 18.02 GiB memory in use. Of the allocated memory 9.20 GiB is allocated by PyTorch, and 8.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/zhangsurui/Project_E2E/V2_GRU_model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B121.46.250.130/home/zhangsurui/Project_E2E/V2_GRU_model.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.53 GiB. GPU 0 has a total capacty of 23.65 GiB of which 4.56 GiB is free. Process 137184 has 1.05 GiB memory in use. Including non-PyTorch memory, this process has 18.02 GiB memory in use. Of the allocated memory 9.20 GiB is allocated by PyTorch, and 8.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a custom Pearson correlation loss\n",
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred_mean = torch.mean(y_pred)\n",
    "        y_true_mean = torch.mean(y_true)\n",
    "        y_pred_std = torch.std(y_pred)\n",
    "        y_true_std = torch.std(y_true)\n",
    "\n",
    "        covariance = torch.mean((y_pred - y_pred_mean) * (y_true - y_true_mean))\n",
    "        correlation = covariance / (y_pred_std * y_true_std)\n",
    "\n",
    "        # Return the negative of Pearson correlation for minimization\n",
    "        return -correlation\n",
    "\n",
    "# Example GRU model\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.linear(output[-1])\n",
    "        return output\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = GRUNet(input_size, hidden_size, output_size)\n",
    "criterion = PearsonCorrelationLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:31:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:31:00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.663389</td>\n",
       "      <td>1926400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:32:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:32:00</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.68</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.665134</td>\n",
       "      <td>1959100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:33:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:33:00</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.653076</td>\n",
       "      <td>649000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:34:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:34:00</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.647179</td>\n",
       "      <td>532700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:35:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.636993</td>\n",
       "      <td>669800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219673</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:54:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:54:00</td>\n",
       "      <td>33.61</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.607624</td>\n",
       "      <td>11517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219674</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:55:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:55:00</td>\n",
       "      <td>33.61</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.61</td>\n",
       "      <td>33.609957</td>\n",
       "      <td>7412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219675</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:56:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:56:00</td>\n",
       "      <td>33.58</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.587015</td>\n",
       "      <td>17359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219676</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:57:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:57:00</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.58</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.565413</td>\n",
       "      <td>24911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219679</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 15:00:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.550000</td>\n",
       "      <td>30460.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209516 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_code            datetime        date      time   open   high    low  close       vwap     volume\n",
       "0        000001.SZ 2023-12-04 09:31:00  2023-12-04  09:31:00   9.67   9.67   9.65   9.66   9.663389  1926400.0\n",
       "1        000001.SZ 2023-12-04 09:32:00  2023-12-04  09:32:00   9.66   9.68   9.65   9.65   9.665134  1959100.0\n",
       "2        000001.SZ 2023-12-04 09:33:00  2023-12-04  09:33:00   9.66   9.66   9.65   9.65   9.653076   649000.0\n",
       "3        000001.SZ 2023-12-04 09:34:00  2023-12-04  09:34:00   9.65   9.65   9.64   9.65   9.647179   532700.0\n",
       "4        000001.SZ 2023-12-04 09:35:00  2023-12-04  09:35:00   9.64   9.65   9.63   9.64   9.636993   669800.0\n",
       "...            ...                 ...         ...       ...    ...    ...    ...    ...        ...        ...\n",
       "1219673  689009.SH 2023-12-04 14:54:00  2023-12-04  14:54:00  33.61  33.62  33.60  33.60  33.607624    11517.0\n",
       "1219674  689009.SH 2023-12-04 14:55:00  2023-12-04  14:55:00  33.61  33.62  33.60  33.61  33.609957     7412.0\n",
       "1219675  689009.SH 2023-12-04 14:56:00  2023-12-04  14:56:00  33.58  33.62  33.57  33.57  33.587015    17359.0\n",
       "1219676  689009.SH 2023-12-04 14:57:00  2023-12-04  14:57:00  33.57  33.58  33.55  33.57  33.565413    24911.0\n",
       "1219679  689009.SH 2023-12-04 15:00:00  2023-12-04  15:00:00  33.55  33.55  33.55  33.55  33.550000    30460.0\n",
       "\n",
       "[1209516 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mink_0 = pd.read_feather(\"/mnt/data/stocks/mink/by_date/20231204.feather\")\n",
    "data_mink_0[\"stock_code\"] = data_mink_0.order_book_id.map(lambda x:api.code_transf(rqcode=x,verse=False))\n",
    "data_mink_0[\"vwap\"] = data_mink_0.total_turnover / data_mink_0.volume\n",
    "data_mink_0 = data_mink_0[[\"stock_code\", \"datetime\", \"date\", \"time\", \"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]]\n",
    "data_mink_0 = data_mink_0[(data_mink_0.time != \"14:58:00\") & (data_mink_0.time != \"14:59:00\")]\n",
    "data_mink_0.loc[data_mink_0.volume == 0, \"vwap\"] = data_mink_0.loc[data_mink_0.volume == 0, \"open\"]\n",
    "data_mink_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_pre_process(group):\n",
    "    price_adj = group.open.tolist()[0]\n",
    "    group.open = group.open / price_adj\n",
    "    group.high = group.high / price_adj\n",
    "    group.low = group.low / price_adj\n",
    "    group.close = group.close / price_adj\n",
    "    group.vwap = group.vwap / price_adj\n",
    "\n",
    "    volume_adj = group.volume.mean()\n",
    "    if volume_adj < 1e-14:\n",
    "        volume_adj = 1\n",
    "    group.volume = group.volume / volume_adj\n",
    "\n",
    "    return group\n",
    "\n",
    "def cs_pre_process(group):\n",
    "    if group.open.std() < 1e-14:\n",
    "        group.open = 0\n",
    "    else:\n",
    "        group.open = (group.open - group.open.mean()) / group.open.std()\n",
    "    group.high = (group.high - group.high.mean()) / group.high.std()\n",
    "    group.low = (group.low - group.low.mean()) / group.low.std()\n",
    "    group.close = (group.close - group.close.mean()) / group.close.std()\n",
    "    group.vwap = (group.vwap - group.vwap.mean()) / group.vwap.std()\n",
    "\n",
    "    if group.volume.std() < 1e-14:\n",
    "        group.volume = 0\n",
    "    else:\n",
    "        group.volume = (group.volume - group.volume.mean()) / group.volume.std()\n",
    "\n",
    "    return group\n",
    "\n",
    "def process_stock(stock_seq):\n",
    "    stock = stack_index[stock_seq]\n",
    "    if stock in df_rtn.index:\n",
    "        stock_rtn = df_rtn.loc[stock, \"return_5\"]\n",
    "        if ~np.isnan(stock_rtn):\n",
    "            y = stock_rtn\n",
    "            return y, stock_seq, stock\n",
    "    return None, None, None\n",
    "    \n",
    "n_jobs = 150\n",
    "window_size = 5\n",
    "train_sample_list = []\n",
    "train_index_list = []\n",
    "test_sample_list = []\n",
    "test_index_list = []\n",
    "\n",
    "date_seq = window_size-1\n",
    "date_current = date_list[date_seq]\n",
    "df_rtn = df_return.loc[df_return.date == date_current, [\"stock_code\", \"return_5\"]].set_index(\"stock_code\")\n",
    "data_type = \"train\" if date_current.strftime(\"%Y-%m-%d\") < \"2022-01-01\" else \"test\"\n",
    "\n",
    "date_window = date_list[date_seq-window_size+1:date_seq+1]\n",
    "window_stack = []\n",
    "for date in date_window:\n",
    "    data_mink = pd.read_feather(\"/mnt/data/stocks/mink/by_date/\"+date.strftime(\"%Y%m%d\")+\".feather\")\n",
    "    data_mink[\"stock_code\"] = data_mink.order_book_id.map(lambda x:api.code_transf(rqcode=x,verse=False))\n",
    "    data_mink[\"vwap\"] = data_mink.total_turnover / data_mink.volume\n",
    "    data_mink = data_mink[[\"stock_code\", \"datetime\", \"date\", \"time\", \"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]]\n",
    "    data_mink = data_mink[(data_mink.time != \"14:58:00\") & (data_mink.time != \"14:59:00\")]\n",
    "    data_mink.loc[data_mink.volume == 0, \"vwap\"] = data_mink.loc[data_mink.volume == 0, \"open\"]\n",
    "    window_stack.append(data_mink)\n",
    "df_window = pd.concat(window_stack, axis=0)\n",
    "if df_window.isna().any().any():\n",
    "    print(\"The window \" + date_current.strftime(\"%Y%m%d\") + \" contains unexpected NaN\")\n",
    "stack_index = []\n",
    "stack_numpy = []\n",
    "for df in df_window.groupby(\"stock_code\"):\n",
    "    if len(df[1]) == 1190:\n",
    "        stack_index.append(df[0])\n",
    "        stack_numpy.append(df[1][[\"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]].to_numpy())\n",
    "stack_numpy = np.array(stack_numpy)\n",
    "# ts_pre_process\n",
    "price_adj = np.tile(stack_numpy[:,0,0][:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "for price in range(5):\n",
    "    stack_numpy[:,:,price] /= price_adj\n",
    "volume_adj = stack_numpy[:,:,5].mean(axis=1)\n",
    "volume_adj = np.tile(np.where(volume_adj < 1e-14, 1, volume_adj)[:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "stack_numpy[:,:,5] /= volume_adj\n",
    "# cs_pre_process\n",
    "for feat in range(6):\n",
    "    cs_mean = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "    cs_std = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "    stack_numpy[:,:,feat] = np.where(cs_std < 1e-14, np.zeros_like(stack_numpy[:,:,feat]), (stack_numpy[:,:,feat] - cs_mean) / cs_std)\n",
    "\n",
    "# # df_window = df_window.groupby(\"stock_code\").apply(ts_pre_process).reset_index(drop=True)\n",
    "# # df_window = df_window.groupby(\"datetime\").apply(cs_pre_process).reset_index(drop=True)\n",
    "# # df_window.to_feather(\"/mnt/research/data/temp/zhangsurui/E2E_NN/Round2/\"+data_type+\"/\"+date_current.strftime(\"%Y%m%d\")+\"_\"+data_type+\".feather\")\n",
    "\n",
    "pool = Pool(n_jobs)\n",
    "results = pool.map(process_stock, range(len(stack_index)))\n",
    "pool.close()\n",
    "pool.join()\n",
    "batch_list = []\n",
    "batch_y = []\n",
    "batch_code = []\n",
    "for result in results:\n",
    "    y, index, code = result\n",
    "    if y is not None:\n",
    "        batch_y.append(y)\n",
    "        batch_list.append(index)\n",
    "        batch_code.append(code)\n",
    "batch_X = torch.Tensor(stack_numpy[batch_list])\n",
    "batch_y = torch.Tensor(np.array(batch_y)[:,np.newaxis])\n",
    "\n",
    "if data_type == \"train\":\n",
    "    train_sample_list.append((batch_X, batch_y))\n",
    "    train_index_list.append(batch_code)\n",
    "else:\n",
    "    test_sample_list.append((batch_X, batch_y))\n",
    "    test_index_list.append(batch_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
