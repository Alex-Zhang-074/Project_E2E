{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('expand_frame_repr', True) \n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 180) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数: read_stk_data 运行了 0.0082秒\n",
      "函数: read_stk_data 运行了 2.8756秒\n",
      "函数: read_stk_data 运行了 0.0043秒\n",
      "函数: read_stk_data 运行了 2.8428秒\n"
     ]
    }
   ],
   "source": [
    "from data_api import DataFeeder, DataAPI\n",
    "from factor_base import FactorBase\n",
    "\n",
    "# Instantiate the data interface\n",
    "d = DataFeeder() \n",
    "api = DataAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>return_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.039761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.059640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.028410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>-0.031289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053977</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.023394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053978</th>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.069582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053979</th>\n",
       "      <td>2023-11-24</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.045808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053980</th>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.017599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053981</th>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>689009.SH</td>\n",
       "      <td>-0.032242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10053982 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date stock_code  return_5\n",
       "0        2016-01-04  000001.SZ -0.039761\n",
       "1        2016-01-05  000001.SZ -0.059640\n",
       "2        2016-01-06  000001.SZ -0.028410\n",
       "3        2016-01-07  000001.SZ -0.043834\n",
       "4        2016-01-08  000001.SZ -0.031289\n",
       "...             ...        ...       ...\n",
       "10053977 2023-11-22  689009.SH -0.023394\n",
       "10053978 2023-11-23  689009.SH -0.069582\n",
       "10053979 2023-11-24  689009.SH -0.045808\n",
       "10053980 2023-11-27  689009.SH -0.017599\n",
       "10053981 2023-11-28  689009.SH -0.032242\n",
       "\n",
       "[10053982 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"/mnt/data/stocks/basic/processed_stock_trade_data.feather\")\n",
    "data = data[data.date >= \"2016-01-01\"][['date', 'stock_code', 'open', 'high', 'low', 'close', 'volume', 'total_turnover']]\n",
    "data['vwap'] = data.total_turnover / data.volume\n",
    "date_list = data.date.unique().tolist()\n",
    "def process_stock_group(group):\n",
    "    group = group[['date', 'vwap']].copy()\n",
    "    group.set_index('date', inplace=True)\n",
    "    group = group.reindex(date_list)\n",
    "    group[\"return_5\"] = (group.vwap.shift(-4) / group.vwap - 1).shift(-1)\n",
    "    return group.iloc[:-5,:]\n",
    "df_return = data.groupby('stock_code').apply(process_stock_group).reset_index()\n",
    "df_return.rename(columns={'level_1': 'date'}, inplace=True)\n",
    "df_return = df_return[['date', 'stock_code', 'return_5']]\n",
    "df_return.to_feather(\"/mnt/research/data/temp/zhangsurui/E2E_NN/Round2/return_data.feather\")\n",
    "df_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:58<00:00, 59.10s/it]\n"
     ]
    }
   ],
   "source": [
    "def process_stock(stock_seq):\n",
    "    stock = stack_index[stock_seq]\n",
    "    if stock in df_rtn.index:\n",
    "        stock_rtn = df_rtn.loc[stock, \"return_5\"]\n",
    "        if ~np.isnan(stock_rtn):\n",
    "            y = stock_rtn\n",
    "            return y, stock_seq, stock\n",
    "    return None, None, None\n",
    "\n",
    "n_jobs = 150\n",
    "window_size = 5\n",
    "train_sample_list = []\n",
    "train_index_list = []\n",
    "test_sample_list = []\n",
    "test_index_list = []\n",
    "\n",
    "for date_seq in tqdm(range(window_size-1,window_size+1)):#len(date_list))):\n",
    "    \n",
    "    date_current = date_list[date_seq]\n",
    "    df_rtn = df_return.loc[df_return.date == date_current, [\"stock_code\", \"return_5\"]].set_index(\"stock_code\")\n",
    "    data_type = \"train\" if date_current.strftime(\"%Y-%m-%d\") < \"2022-01-01\" else \"test\"\n",
    "\n",
    "    date_window = date_list[date_seq-window_size+1:date_seq+1]\n",
    "    window_stack = []\n",
    "    for date in date_window:\n",
    "        data_mink = pd.read_feather(\"/mnt/data/stocks/mink/by_date/\"+date.strftime(\"%Y%m%d\")+\".feather\")\n",
    "        data_mink[\"stock_code\"] = data_mink.order_book_id.map(lambda x:api.code_transf(rqcode=x,verse=False))\n",
    "        data_mink[\"vwap\"] = data_mink.total_turnover / data_mink.volume\n",
    "        data_mink = data_mink[[\"stock_code\", \"datetime\", \"date\", \"time\", \"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]]\n",
    "        data_mink = data_mink[(data_mink.time != \"14:58:00\") & (data_mink.time != \"14:59:00\")]\n",
    "        data_mink.loc[data_mink.volume == 0, \"vwap\"] = data_mink.loc[data_mink.volume == 0, \"open\"]\n",
    "        window_stack.append(data_mink)\n",
    "    df_window = pd.concat(window_stack, axis=0)\n",
    "    if df_window.isna().any().any():\n",
    "        print(\"The window \" + date_current.strftime(\"%Y%m%d\") + \" contains unexpected NaN\")\n",
    "    stack_index = []\n",
    "    stack_numpy = []\n",
    "    for df in df_window.groupby(\"stock_code\"):\n",
    "        if len(df[1]) == 1190:\n",
    "            stack_index.append(df[0])\n",
    "            stack_numpy.append(df[1][[\"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]].to_numpy())\n",
    "    stack_numpy = np.array(stack_numpy)\n",
    "    # ts_pre_process\n",
    "    price_adj = np.tile(stack_numpy[:,0,0][:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "    for price in range(5):\n",
    "        stack_numpy[:,:,price] /= price_adj\n",
    "    volume_adj = stack_numpy[:,:,5].mean(axis=1)\n",
    "    volume_adj = np.tile(np.where(volume_adj < 1e-14, 1, volume_adj)[:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "    stack_numpy[:,:,5] /= volume_adj\n",
    "    # cs_pre_process\n",
    "    for feat in range(6):\n",
    "        cs_mean = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "        cs_std = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "        stack_numpy[:,:,feat] = np.where(cs_std < 1e-14, np.zeros_like(stack_numpy[:,:,feat]), (stack_numpy[:,:,feat] - cs_mean) / cs_std)\n",
    "\n",
    "    # # df_window = df_window.groupby(\"stock_code\").apply(ts_pre_process).reset_index(drop=True)\n",
    "    # # df_window = df_window.groupby(\"datetime\").apply(cs_pre_process).reset_index(drop=True)\n",
    "    # # df_window.to_feather(\"/mnt/research/data/temp/zhangsurui/E2E_NN/Round2/\"+data_type+\"/\"+date_current.strftime(\"%Y%m%d\")+\"_\"+data_type+\".feather\")\n",
    "\n",
    "    pool = Pool(n_jobs)\n",
    "    results = pool.map(process_stock, range(len(stack_index)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    batch_list = []\n",
    "    batch_y = []\n",
    "    batch_code = []\n",
    "    for result in results:\n",
    "        y, index, code = result\n",
    "        if y is not None:\n",
    "            batch_y.append(y)\n",
    "            batch_list.append(index)\n",
    "            batch_code.append(code)\n",
    "    batch_X = torch.Tensor(stack_numpy[batch_list])\n",
    "\n",
    "    if data_type == \"train\":\n",
    "        train_sample_list.append((batch_X, batch_y))\n",
    "        train_index_list.append(batch_code)\n",
    "    else:\n",
    "        test_sample_list.append((batch_X, batch_y))\n",
    "        test_index_list.append(batch_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_pre_process(group):\n",
    "    price_adj = group.open.tolist()[0]\n",
    "    group.open = group.open / price_adj\n",
    "    group.high = group.high / price_adj\n",
    "    group.low = group.low / price_adj\n",
    "    group.close = group.close / price_adj\n",
    "    group.vwap = group.vwap / price_adj\n",
    "\n",
    "    volume_adj = group.volume.mean()\n",
    "    if volume_adj < 1e-14:\n",
    "        volume_adj = 1\n",
    "    group.volume = group.volume / volume_adj\n",
    "\n",
    "    return group\n",
    "\n",
    "def cs_pre_process(group):\n",
    "    if group.open.std() < 1e-14:\n",
    "        group.open = 0\n",
    "    else:\n",
    "        group.open = (group.open - group.open.mean()) / group.open.std()\n",
    "    group.high = (group.high - group.high.mean()) / group.high.std()\n",
    "    group.low = (group.low - group.low.mean()) / group.low.std()\n",
    "    group.close = (group.close - group.close.mean()) / group.close.std()\n",
    "    group.vwap = (group.vwap - group.vwap.mean()) / group.vwap.std()\n",
    "\n",
    "    if group.volume.std() < 1e-14:\n",
    "        group.volume = 0\n",
    "    else:\n",
    "        group.volume = (group.volume - group.volume.mean()) / group.volume.std()\n",
    "\n",
    "    return group\n",
    "\n",
    "def process_stock(stock_seq):\n",
    "    stock = stack_index[stock_seq]\n",
    "    if stock in df_rtn.index:\n",
    "        stock_rtn = df_rtn.loc[stock, \"return_5\"]\n",
    "        if ~np.isnan(stock_rtn):\n",
    "            y = stock_rtn\n",
    "            return y, stock_seq, stock\n",
    "    return None, None, None\n",
    "    \n",
    "n_jobs = 150\n",
    "window_size = 5\n",
    "train_sample_list = []\n",
    "train_index_list = []\n",
    "test_sample_list = []\n",
    "test_index_list = []\n",
    "\n",
    "date_seq = window_size-1\n",
    "date_current = date_list[date_seq]\n",
    "df_rtn = df_return.loc[df_return.date == date_current, [\"stock_code\", \"return_5\"]].set_index(\"stock_code\")\n",
    "data_type = \"train\" if date_current.strftime(\"%Y-%m-%d\") < \"2022-01-01\" else \"test\"\n",
    "\n",
    "date_window = date_list[date_seq-window_size+1:date_seq+1]\n",
    "window_stack = []\n",
    "for date in date_window:\n",
    "    data_mink = pd.read_feather(\"/mnt/data/stocks/mink/by_date/\"+date.strftime(\"%Y%m%d\")+\".feather\")\n",
    "    data_mink[\"stock_code\"] = data_mink.order_book_id.map(lambda x:api.code_transf(rqcode=x,verse=False))\n",
    "    data_mink[\"vwap\"] = data_mink.total_turnover / data_mink.volume\n",
    "    data_mink = data_mink[[\"stock_code\", \"datetime\", \"date\", \"time\", \"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]]\n",
    "    data_mink = data_mink[(data_mink.time != \"14:58:00\") & (data_mink.time != \"14:59:00\")]\n",
    "    data_mink.loc[data_mink.volume == 0, \"vwap\"] = data_mink.loc[data_mink.volume == 0, \"open\"]\n",
    "    window_stack.append(data_mink)\n",
    "df_window = pd.concat(window_stack, axis=0)\n",
    "if df_window.isna().any().any():\n",
    "    print(\"The window \" + date_current.strftime(\"%Y%m%d\") + \" contains unexpected NaN\")\n",
    "stack_index = []\n",
    "stack_numpy = []\n",
    "for df in df_window.groupby(\"stock_code\"):\n",
    "    if len(df[1]) == 1190:\n",
    "        stack_index.append(df[0])\n",
    "        stack_numpy.append(df[1][[\"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]].to_numpy())\n",
    "stack_numpy = np.array(stack_numpy)\n",
    "# ts_pre_process\n",
    "price_adj = np.tile(stack_numpy[:,0,0][:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "for price in range(5):\n",
    "    stack_numpy[:,:,price] /= price_adj\n",
    "volume_adj = stack_numpy[:,:,5].mean(axis=1)\n",
    "volume_adj = np.tile(np.where(volume_adj < 1e-14, 1, volume_adj)[:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "stack_numpy[:,:,5] /= volume_adj\n",
    "# cs_pre_process\n",
    "for feat in range(6):\n",
    "    cs_mean = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "    cs_std = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "    stack_numpy[:,:,feat] = np.where(cs_std < 1e-14, np.zeros_like(stack_numpy[:,:,feat]), (stack_numpy[:,:,feat] - cs_mean) / cs_std)\n",
    "\n",
    "# # df_window = df_window.groupby(\"stock_code\").apply(ts_pre_process).reset_index(drop=True)\n",
    "# # df_window = df_window.groupby(\"datetime\").apply(cs_pre_process).reset_index(drop=True)\n",
    "# # df_window.to_feather(\"/mnt/research/data/temp/zhangsurui/E2E_NN/Round2/\"+data_type+\"/\"+date_current.strftime(\"%Y%m%d\")+\"_\"+data_type+\".feather\")\n",
    "\n",
    "pool = Pool(n_jobs)\n",
    "results = pool.map(process_stock, range(len(stack_index)))\n",
    "pool.close()\n",
    "pool.join()\n",
    "batch_list = []\n",
    "batch_y = []\n",
    "batch_code = []\n",
    "for result in results:\n",
    "    y, index, code = result\n",
    "    if y is not None:\n",
    "        batch_y.append(y)\n",
    "        batch_list.append(index)\n",
    "        batch_code.append(code)\n",
    "batch_X = torch.Tensor(stack_numpy[batch_list])\n",
    "\n",
    "if data_type == \"train\":\n",
    "    train_sample_list.append((batch_X, batch_y))\n",
    "    train_index_list.append(batch_code)\n",
    "else:\n",
    "    test_sample_list.append((batch_X, batch_y))\n",
    "    test_index_list.append(batch_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1190, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_numpy[[0,2]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_index = []\n",
    "stack_numpy = []\n",
    "for df in df_window.groupby(\"stock_code\"):\n",
    "    if len(df[1]) == 1190:\n",
    "        stack_index.append(df[0])\n",
    "        stack_numpy.append(df[1][[\"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]].to_numpy())\n",
    "stack_numpy = np.array(stack_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.        ,  1.0025    ,  0.99916667,  0.99916667,\n",
       "          1.00021267,  3.03686472],\n",
       "        [ 0.99916667,  0.99916667,  0.99666667,  0.9975    ,\n",
       "          0.99864011,  2.95327965],\n",
       "        [ 0.9975    ,  0.99916667,  0.99666667,  0.99916667,\n",
       "          0.99797085,  1.64204107],\n",
       "        ...,\n",
       "        [ 0.92666667,  0.92833333,  0.92666667,  0.9275    ,\n",
       "          0.92724031,  0.82995438],\n",
       "        [ 0.92833333,  0.92833333,  0.92666667,  0.92666667,\n",
       "          0.92752923,  1.51696274],\n",
       "        [ 0.9275    ,  0.9275    ,  0.92666667,  0.92666667,\n",
       "          0.92666671,  1.90666161]],\n",
       "\n",
       "       [[ 1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  0.        ]],\n",
       "\n",
       "       [[ 1.        ,  1.01525054,  0.99803922,  1.00217865,\n",
       "          0.9999693 ,  2.93064603],\n",
       "        [ 1.01198257,  1.01198257,  1.00217865,  1.01089325,\n",
       "          1.00356708,  0.59418597],\n",
       "        [ 1.01089325,  1.01089325,  1.00217865,  1.00849673,\n",
       "          1.00633582,  0.29820079],\n",
       "        ...,\n",
       "        [ 0.77385621,  0.77755991,  0.77385621,  0.77755991,\n",
       "          0.77557256,  0.41290889],\n",
       "        [ 0.77342048,  0.77755991,  0.77298475,  0.77298475,\n",
       "          0.77553971,  1.32936521],\n",
       "        [ 0.77298475,  0.77298475,  0.77298475,  0.77298475,\n",
       "          0.77298475,  1.42000375]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.        ,  1.00225394,  0.9947408 ,  0.99586777,\n",
       "          0.99794838,  4.97962771],\n",
       "        [ 0.99586777,  0.99812171,  0.99586777,  0.99661908,\n",
       "          0.99616374,  1.77514506],\n",
       "        [ 0.99661908,  1.00300526,  0.99661908,  0.99924869,\n",
       "          0.99718257,  1.96726033],\n",
       "        ...,\n",
       "        [ 0.78850488,  0.78850488,  0.78812923,  0.78850488,\n",
       "          0.78840635,  0.9375225 ],\n",
       "        [ 0.78850488,  0.78888054,  0.78850488,  0.78850488,\n",
       "          0.78855299,  1.26027615],\n",
       "        [ 0.78700225,  0.78700225,  0.78512397,  0.78625094,\n",
       "          0.78627529,  0.82993795]],\n",
       "\n",
       "       [[ 1.        ,  1.02035522,  0.99780483,  1.00758332,\n",
       "          1.00481246,  3.5785523 ],\n",
       "        [ 1.0173618 ,  1.0173618 ,  1.00019956,  1.00019956,\n",
       "          1.00439658,  1.41374906],\n",
       "        [ 1.00319298,  1.016364  ,  1.00319298,  1.016364  ,\n",
       "          1.00560642,  0.47124969],\n",
       "        ...,\n",
       "        [ 0.78866494,  0.79185791,  0.78846538,  0.79185791,\n",
       "          0.79021241,  0.8394135 ],\n",
       "        [ 0.79185791,  0.79185791,  0.79066055,  0.79066055,\n",
       "          0.79145879,  0.17671863],\n",
       "        [ 0.78906406,  0.79145879,  0.7888645 ,  0.79006186,\n",
       "          0.79015742,  1.19240897]],\n",
       "\n",
       "       [[ 1.        ,  1.02201867,  0.9707592 ,  1.0128589 ,\n",
       "          0.99945064, 30.87010277],\n",
       "        [ 1.02166637,  1.02360402,  1.00405144,  1.00422758,\n",
       "          1.01234515, 11.40335554],\n",
       "        [ 1.00757442,  1.03928131,  1.00757442,  1.03928131,\n",
       "          1.02241175,  7.5548457 ],\n",
       "        ...,\n",
       "        [ 1.0974106 ,  1.10375198,  1.09705831,  1.10375198,\n",
       "          1.100836  ,  1.54671221],\n",
       "        [ 1.10551348,  1.10639422,  1.10375198,  1.10428043,\n",
       "          1.10536601,  1.93544146],\n",
       "        [ 1.09212612,  1.0974106 ,  1.09194997,  1.09265457,\n",
       "          1.09264207,  2.59057268]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_adj = np.tile(stack_numpy[:,0,0][:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "for price in range(5):\n",
    "    stack_numpy[:,:,price] /= price_adj\n",
    "volume_adj = stack_numpy[:,:,5].mean(axis=1)\n",
    "volume_adj = np.tile(np.where(volume_adj < 1e-14, 1, volume_adj)[:,np.newaxis], (1,stack_numpy.shape[1]))\n",
    "stack_numpy[:,:,5] /= volume_adj\n",
    "stack_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00,  1.74732450e+02,  1.62073142e+02,\n",
       "          1.42466780e+02,  3.10300316e+02, -4.94967366e-01],\n",
       "        [ 1.30320334e+02,  1.24022201e+02,  1.18176344e+02,\n",
       "          1.19637115e+02,  1.28261577e+02,  1.63917026e-01],\n",
       "        [ 1.14272741e+02,  1.10745924e+02,  1.06381424e+02,\n",
       "          1.06608291e+02,  1.11144693e+02,  3.27889133e-02],\n",
       "        ...,\n",
       "        [ 7.97780243e+00,  8.00292446e+00,  7.96181674e+00,\n",
       "          7.97817043e+00,  7.97944862e+00, -3.94487419e-01],\n",
       "        [ 7.98676947e+00,  7.99776655e+00,  7.94878509e+00,\n",
       "          7.96413150e+00,  7.97286339e+00,  6.44946750e-02],\n",
       "        [ 7.97291173e+00,  7.98069770e+00,  7.95276898e+00,\n",
       "          7.96157022e+00,  7.96171829e+00, -2.63287447e-01]],\n",
       "\n",
       "       [[ 0.00000000e+00,  1.74294215e+02,  1.62209149e+02,\n",
       "          1.42586436e+02,  3.10234127e+02, -1.00000000e+00],\n",
       "        [ 1.30429859e+02,  1.24126473e+02,  1.18574928e+02,\n",
       "          1.19939463e+02,  1.28437597e+02, -1.00000000e+00],\n",
       "        [ 1.14561645e+02,  1.10839124e+02,  1.06740559e+02,\n",
       "          1.06698039e+02,  1.11372714e+02, -1.00000000e+00],\n",
       "        ...,\n",
       "        [ 8.68827601e+00,  8.69794377e+00,  8.67102526e+00,\n",
       "          8.67996811e+00,  8.68405763e+00, -1.00000000e+00],\n",
       "        [ 8.68054162e+00,  8.69238767e+00,  8.65696232e+00,\n",
       "          8.67352320e+00,  8.67394134e+00, -1.00000000e+00],\n",
       "        [ 8.67429836e+00,  8.68269294e+00,  8.66126149e+00,\n",
       "          8.67075923e+00,  8.67091861e+00, -1.00000000e+00]],\n",
       "\n",
       "       [[ 0.00000000e+00,  1.76967547e+02,  1.61889131e+02,\n",
       "          1.42899260e+02,  3.10224573e+02, -5.12631605e-01],\n",
       "        [ 1.32004726e+02,  1.25625810e+02,  1.18835439e+02,\n",
       "          1.21256887e+02,  1.28899311e+02, -7.65825373e-01],\n",
       "        [ 1.15820486e+02,  1.12057415e+02,  1.06975288e+02,\n",
       "          1.07613120e+02,  1.12084687e+02, -8.12441678e-01],\n",
       "        ...,\n",
       "        [ 6.49733254e+00,  6.54073231e+00,  6.48398294e+00,\n",
       "          6.52675516e+00,  6.51068936e+00, -6.98752686e-01],\n",
       "        [ 6.48712914e+00,  6.53641211e+00,  6.46468460e+00,\n",
       "          6.47748591e+00,  6.50252567e+00, -6.71476982e-02],\n",
       "        [ 6.47808509e+00,  6.48457398e+00,  6.46800779e+00,\n",
       "          6.47534940e+00,  6.47547260e+00, -4.51326561e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.00000000e+00,  1.74689318e+02,  1.61350799e+02,\n",
       "          1.41993103e+02,  3.09595592e+02, -1.71884582e-01],\n",
       "        [ 1.29886760e+02,  1.23891450e+02,  1.18080816e+02,\n",
       "          1.19530577e+02,  1.27941041e+02, -3.00397590e-01],\n",
       "        [ 1.14170940e+02,  1.11175229e+02,  1.06376297e+02,\n",
       "          1.06617124e+02,  1.11056112e+02,  2.37340952e-01],\n",
       "        ...,\n",
       "        [ 6.63925294e+00,  6.64687602e+00,  6.62201765e+00,\n",
       "          6.63270213e+00,  6.63497253e+00, -3.16008588e-01],\n",
       "        [ 6.63315434e+00,  6.64613603e+00,  6.61456195e+00,\n",
       "          6.62762028e+00,  6.62841533e+00, -1.15629402e-01],\n",
       "        [ 6.61369461e+00,  6.62030117e+00,  6.58528794e+00,\n",
       "          6.60364353e+00,  6.60400431e+00, -6.79321332e-01]],\n",
       "\n",
       "       [[ 0.00000000e+00,  1.77862367e+02,  1.61850877e+02,\n",
       "          1.43675297e+02,  3.11731928e+02, -4.04884360e-01],\n",
       "        [ 1.32711718e+02,  1.26298894e+02,  1.18598790e+02,\n",
       "          1.19963598e+02,  1.29006680e+02, -4.42827368e-01],\n",
       "        [ 1.14930630e+02,  1.12669259e+02,  1.07084572e+02,\n",
       "          1.08460410e+02,  1.12002723e+02, -7.03599709e-01],\n",
       "        ...,\n",
       "        [ 6.64080359e+00,  6.67939351e+00,  6.62526857e+00,\n",
       "          6.66515934e+00,  6.65246252e+00, -3.87586297e-01],\n",
       "        [ 6.66561348e+00,  6.67499387e+00,  6.63537911e+00,\n",
       "          6.64847314e+00,  6.65652591e+00, -8.75991653e-01],\n",
       "        [ 6.63364113e+00,  6.66345244e+00,  6.62142619e+00,\n",
       "          6.64049806e+00,  6.64154808e+00, -5.39266617e-01]],\n",
       "\n",
       "       [[ 0.00000000e+00,  1.78153961e+02,  1.57436784e+02,\n",
       "          1.44432800e+02,  3.10063147e+02,  4.13371873e+00],\n",
       "        [ 1.33277467e+02,  1.27079960e+02,  1.19059378e+02,\n",
       "          1.20450745e+02,  1.30035524e+02,  3.49417638e+00],\n",
       "        [ 1.15436957e+02,  1.15232311e+02,  1.07556632e+02,\n",
       "          1.10928559e+02,  1.13891184e+02,  3.75174527e+00],\n",
       "        ...,\n",
       "        [ 9.63201682e+00,  9.70412465e+00,  9.60967858e+00,\n",
       "          9.68428399e+00,  9.66055928e+00,  1.28439976e-01],\n",
       "        [ 9.70196921e+00,  9.72360172e+00,  9.65889130e+00,\n",
       "          9.68228236e+00,  9.69324597e+00,  3.58152752e-01],\n",
       "        [ 9.56555396e+00,  9.62588991e+00,  9.54961422e+00,\n",
       "          9.56679928e+00,  9.56685251e+00,  9.68077560e-04]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feat in range(6):\n",
    "    cs_mean = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "    cs_std = np.tile(stack_numpy[:,:,feat].std(axis=0)[np.newaxis,:], (stack_numpy.shape[0],1))\n",
    "    stack_numpy[:,:,feat] = np.where(cs_std < 1e-14, np.zeros_like(stack_numpy[:,:,feat]), (stack_numpy[:,:,feat] - cs_mean) / cs_std)\n",
    "stack_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vwap</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:31:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:31:00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.663389</td>\n",
       "      <td>1926400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:32:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:32:00</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.68</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.665134</td>\n",
       "      <td>1959100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:33:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:33:00</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.66</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.653076</td>\n",
       "      <td>649000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:34:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:34:00</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.647179</td>\n",
       "      <td>532700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2023-12-04 09:35:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.64</td>\n",
       "      <td>9.636993</td>\n",
       "      <td>669800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219673</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:54:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:54:00</td>\n",
       "      <td>33.61</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.607624</td>\n",
       "      <td>11517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219674</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:55:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:55:00</td>\n",
       "      <td>33.61</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.61</td>\n",
       "      <td>33.609957</td>\n",
       "      <td>7412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219675</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:56:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:56:00</td>\n",
       "      <td>33.58</td>\n",
       "      <td>33.62</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.587015</td>\n",
       "      <td>17359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219676</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 14:57:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>14:57:00</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.58</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.57</td>\n",
       "      <td>33.565413</td>\n",
       "      <td>24911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219679</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>2023-12-04 15:00:00</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.550000</td>\n",
       "      <td>30460.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209516 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_code            datetime        date      time   open   high    low  close       vwap     volume\n",
       "0        000001.SZ 2023-12-04 09:31:00  2023-12-04  09:31:00   9.67   9.67   9.65   9.66   9.663389  1926400.0\n",
       "1        000001.SZ 2023-12-04 09:32:00  2023-12-04  09:32:00   9.66   9.68   9.65   9.65   9.665134  1959100.0\n",
       "2        000001.SZ 2023-12-04 09:33:00  2023-12-04  09:33:00   9.66   9.66   9.65   9.65   9.653076   649000.0\n",
       "3        000001.SZ 2023-12-04 09:34:00  2023-12-04  09:34:00   9.65   9.65   9.64   9.65   9.647179   532700.0\n",
       "4        000001.SZ 2023-12-04 09:35:00  2023-12-04  09:35:00   9.64   9.65   9.63   9.64   9.636993   669800.0\n",
       "...            ...                 ...         ...       ...    ...    ...    ...    ...        ...        ...\n",
       "1219673  689009.SH 2023-12-04 14:54:00  2023-12-04  14:54:00  33.61  33.62  33.60  33.60  33.607624    11517.0\n",
       "1219674  689009.SH 2023-12-04 14:55:00  2023-12-04  14:55:00  33.61  33.62  33.60  33.61  33.609957     7412.0\n",
       "1219675  689009.SH 2023-12-04 14:56:00  2023-12-04  14:56:00  33.58  33.62  33.57  33.57  33.587015    17359.0\n",
       "1219676  689009.SH 2023-12-04 14:57:00  2023-12-04  14:57:00  33.57  33.58  33.55  33.57  33.565413    24911.0\n",
       "1219679  689009.SH 2023-12-04 15:00:00  2023-12-04  15:00:00  33.55  33.55  33.55  33.55  33.550000    30460.0\n",
       "\n",
       "[1209516 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mink_0 = pd.read_feather(\"/mnt/data/stocks/mink/by_date/20231204.feather\")\n",
    "data_mink_0[\"stock_code\"] = data_mink_0.order_book_id.map(lambda x:api.code_transf(rqcode=x,verse=False))\n",
    "data_mink_0[\"vwap\"] = data_mink_0.total_turnover / data_mink_0.volume\n",
    "data_mink_0 = data_mink_0[[\"stock_code\", \"datetime\", \"date\", \"time\", \"open\", \"high\", \"low\", \"close\", \"vwap\", \"volume\"]]\n",
    "data_mink_0 = data_mink_0[(data_mink_0.time != \"14:58:00\") & (data_mink_0.time != \"14:59:00\")]\n",
    "data_mink_0.loc[data_mink_0.volume == 0, \"vwap\"] = data_mink_0.loc[data_mink_0.volume == 0, \"open\"]\n",
    "data_mink_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_sample_list[0][0][0].squeeze()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 1190 at dim 1 (got 714)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/zhangsurui/Project_E2E/V2_GRU_model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B121.46.250.130/home/zhangsurui/Project_E2E/V2_GRU_model.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([np\u001b[39m.\u001b[39marray(x\u001b[39m.\u001b[39msqueeze()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_sample_list[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B121.46.250.130/home/zhangsurui/Project_E2E/V2_GRU_model.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m X\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 1190 at dim 1 (got 714)"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([np.array(x.squeeze()) for x in train_sample_list[0][0]])\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1190, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_sample_list[0][0][0]\n",
    "x.shape\n",
    "x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred_mean = torch.mean(y_pred)\n",
    "        y_true_mean = torch.mean(y_true)\n",
    "        y_pred_std = torch.std(y_pred)\n",
    "        y_true_std = torch.std(y_true)\n",
    "\n",
    "        cov = torch.mean((y_pred - y_pred_mean) * (y_true - y_true_mean))\n",
    "        IC = cov / (y_pred_std * y_true_std)\n",
    "\n",
    "        return -IC\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1, dropout_rate=0.4,random_seed=0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        # self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # out = self.batch_norm(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = GRUNet(input_size=6, hidden_size=50, num_layers=2, output_size=1, dropout_rate=0.4)\n",
    "criterion = PearsonCorrelationLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "model.to(device)\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for seq, labels in train_sample_list:\n",
    "        seq, labels = seq.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        for X_individual in seq:\n",
    "            y_individual = model(X_individual.float())\n",
    "            \n",
    "        y_pred = model(seq.float())\n",
    "        single_loss = criterion(y_pred.squeeze(), labels.float().squeeze())\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += single_loss.item()\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    test_correct = 0\n",
    "    total_test = 0\n",
    "\n",
    "    for seq, labels in test_loader:\n",
    "        seq, labels = seq.to(device), labels.to(device)\n",
    "        y_pred = model(seq.float())\n",
    "        single_loss = criterion(y_pred.squeeze(), labels.float().squeeze())\n",
    "        \n",
    "        total_test_loss += single_loss.item()\n",
    "        predicted = (y_pred > 0.5).float()\n",
    "        total_test += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    test_loss = total_test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct / total_test\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(test_accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), '/mnt/research/data/temp/zhangsurui/E2E_NN/Round1/model_state_dict.pth')\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a custom Pearson correlation loss\n",
    "class PearsonCorrelationLoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred_mean = torch.mean(y_pred)\n",
    "        y_true_mean = torch.mean(y_true)\n",
    "        y_pred_std = torch.std(y_pred)\n",
    "        y_true_std = torch.std(y_true)\n",
    "\n",
    "        covariance = torch.mean((y_pred - y_pred_mean) * (y_true - y_true_mean))\n",
    "        correlation = covariance / (y_pred_std * y_true_std)\n",
    "\n",
    "        # Return the negative of Pearson correlation for minimization\n",
    "        return -correlation\n",
    "\n",
    "# Example GRU model\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.linear(output[-1])\n",
    "        return output\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = GRUNet(input_size, hidden_size, output_size)\n",
    "criterion = PearsonCorrelationLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
